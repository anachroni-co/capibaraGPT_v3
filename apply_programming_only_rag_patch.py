#!/usr/bin/env python3
"""
Parche para actualizar el LiveMind Orchestrator con el detector RAG solo para programaci√≥n

Este parche modifica el archivo livemind_orchestrator.py para que el RAG
solo se active para consultas de programaci√≥n, no para cualquier tipo de conocimiento.
"""

import re
from pathlib import Path

def patch_livemind_orchestrator():
    """Aplicar parche para usar detector solo de programaci√≥n"""
    
    # Ruta al archivo original
    orchestrator_file = Path("/home/elect/capibara6/arm-axion-optimizations/vllm_integration/livemind_orchestrator.py")
    
    if not orchestrator_file.exists():
        print(f"‚ùå Error: No se encontr√≥ el archivo {orchestrator_file}")
        return False
    
    # Leer el contenido original
    content = orchestrator_file.read_text(encoding='utf-8')
    
    print("üîç Analizando el archivo livemind_orchestrator.py...")
    
    # Importar el nuevo detector al principio del archivo
    import_section = '''import sys
from pathlib import Path
from typing import Dict, List, Optional, Any, AsyncIterator
from dataclasses import dataclass
import asyncio
import time
import numpy as np

sys.path.insert(0, str(Path(__file__).parent.parent))

from vllm_integration.vllm_axion_backend import (
    AxionVLLMEngine,
    AxionMultiExpertVLLM,
    AxionVLLMConfig
)
from vllm_integration.semantic_router import (
    IncrementalSemanticRouter,
    FastDomainClassifier,
    RoutingPrediction
)
'''
    
    # A√±adir la importaci√≥n del nuevo detector
    new_import = '''from vllm_integration.semantic_router import (
    IncrementalSemanticRouter,
    FastDomainClassifier,
    RoutingPrediction
)
from vllm_integration.programming_rag_detector import (
    ProgrammingRAGDetector,
    ProgrammingRAGParallelFetcher as ProgrammingRAGFetcher,
    is_programming_query
)
'''
    
    # Actualizar la importaci√≥n
    updated_content = content.replace(
        'from vllm_integration.semantic_router import (\n    IncrementalSemanticRouter,\n    FastDomainClassifier,\n    RoutingPrediction\n)', 
        'from vllm_integration.semantic_router import (\n    IncrementalSemanticRouter,\n    FastDomainClassifier,\n    RoutingPrediction\n)\nfrom vllm_integration.programming_rag_detector import (\n    ProgrammingRAGDetector,\n    ProgrammingRAGParallelFetcher as ProgrammingRAGFetcher,\n    is_programming_query\n)'
    )
    
    # Si la importaci√≥n a√∫n no existe, la agregaremos
    if 'from vllm_integration.programming_rag_detector' not in updated_content:
        updated_content = content.replace(
            'from vllm_integration.semantic_router import (\n    IncrementalSemanticRouter,\n    FastDomainClassifier,\n    RoutingPrediction\n)',
            'from vllm_integration.semantic_router import (\n    IncrementalSemanticRouter,\n    FastDomainClassifier,\n    RoutingPrediction\n)\nfrom vllm_integration.programming_rag_detector import (\n    ProgrammingRAGDetector,\n    ProgrammingRAGParallelFetcher as ProgrammingRAGFetcher,\n    is_programming_query\n)'
        )
    
    # Actualizar el constructor para usar el nuevo detector
    # Cambiar la inicializaci√≥n del RAG parallel fetcher
    rag_init_pattern_old = r'self\.rag_fetcher = RAGParallelFetcher\(\s*\n\s*bridge_url=rag_bridge_url,\s*\n\s*collection_name=rag_collection,\s*\n\s*enable_rag=True\s*\n\s*\)'
    
    rag_init_pattern_new = '''self.rag_fetcher = ProgrammingRAGFetcher(
                bridge_url=rag_bridge_url,
                collection_name=rag_collection,
                enable_rag=True
            )'''
    
    updated_content = re.sub(
        rag_init_pattern_old.replace('(', '\\(').replace(')', '\\)').replace('\n', '\\n').replace('*', '\\*').replace('+', '\\+'),
        rag_init_pattern_new,
        updated_content,
        flags=re.MULTILINE | re.DOTALL
    )
    
    if "ProgrammingRAGFetcher" not in updated_content:
        # Si no se pudo hacer el reemplazo preciso, intentaremos uno m√°s general
        updated_content = updated_content.replace(
            'RAGParallelFetcher(',
            'ProgrammingRAGFetcher('
        )
    
    # Actualizar tambi√©n el par√°metro enable_rag en la clase
    # Asegurarnos de que el detector solo se inicialice si enable_rag es True
    init_code_pattern = r'if enable_rag:\s*\n(\s+.+?\n)+'
    # Ya deber√≠a estar correcto si hicimos el reemplazo anterior
    
    # Actualizar la secci√≥n de generaci√≥n donde se verifica el RAG
    # En el m√©todo generate, donde se llama a rag_fetcher.detect_and_fetch
    generate_section_old = '''# Phase 1: PARALLEL processing - routing AND RAG fetch
        # Start RAG fetch in parallel (if enabled)
        rag_task = None
        if self.rag_fetcher:
            rag_task = asyncio.create_task(
                self.rag_fetcher.detect_and_fetch(request.prompt, request.request_id)
            )'''
    
    generate_section_new = '''# Phase 1: PARALLEL processing - routing AND Programming RAG fetch
        # Start Programming RAG fetch in parallel (if enabled)
        rag_task = None
        if self.rag_fetcher:
            rag_task = asyncio.create_task(
                self.rag_fetcher.detect_and_fetch(request.prompt, request.request_id)
            )'''
    
    updated_content = updated_content.replace(generate_section_old, generate_section_new)
    
    # Actualizar la parte del c√≥digo que procesa el resultado del RAG
    rag_handling_old = '''# Wait for RAG fetch to complete (if started)
        is_rag_query = False
        rag_context = None
        if rag_task:
            is_rag_query, rag_context = await rag_task
            if rag_context:
                # Inject context into prompt
                request.prompt = self.rag_fetcher.inject_context(request.prompt, rag_context)
                print(f"‚úÖ [{request.request_id}] RAG context injected ({rag_context.tokens_count} tokens)")'''
    
    rag_handling_new = '''# Wait for Programming RAG fetch to complete (if started)
        is_programming_query = False
        rag_context = None
        if rag_task:
            is_programming_query, rag_context = await rag_task
            if rag_context:
                # Inject context into prompt
                request.prompt = self.rag_fetcher.inject_context(request.prompt, rag_context)
                print(f"üíª [{request.request_id}] Programming RAG context injected ({rag_context.tokens_count} tokens)")
            elif is_programming_query:
                print(f"üíª [{request.request_id}] Programming query detected but no RAG context available")'''
    
    updated_content = updated_content.replace(rag_handling_old, rag_handling_new)
    
    # Similar update en la secci√≥n de streaming
    streaming_rag_handling_old = '''# Wait for RAG fetch to complete (if started)
        is_rag_query = False
        rag_context = None
        if rag_task:
            is_rag_query, rag_context = await rag_task
            if rag_context:
                # Inject context into prompt
                request.prompt = self.rag_fetcher.inject_context(request.prompt, rag_context)
                print(f"‚úÖ [{request.request_id}] RAG context injected ({rag_context.tokens_count} tokens)")'''
    
    streaming_rag_handling_new = '''# Wait for Programming RAG fetch to complete (if started)
        is_programming_query = False
        rag_context = None
        if rag_task:
            is_programming_query, rag_context = await rag_task
            if rag_context:
                # Inject context into prompt
                request.prompt = self.rag_fetcher.inject_context(request.prompt, rag_context)
                print(f"üíª [{request.request_id}] Programming RAG context injected ({rag_context.tokens_count} tokens)")
            elif is_programming_query:
                print(f"üíª [{request.request_id}] Programming query detected but no RAG context available")'''
    
    updated_content = updated_content.replace(streaming_rag_handling_old, streaming_rag_handling_new)
    
    # Escribir el contenido actualizado al archivo
    backup_path = str(orchestrator_file) + ".backup_before_programming_rag"
    print(f"üíæ Creando copia de seguridad en: {backup_path}")
    Path(backup_path).write_text(content, encoding='utf-8')
    
    print(f"üìù Escribiendo actualizaci√≥n al archivo: {orchestrator_file}")
    orchestrator_file.write_text(updated_content, encoding='utf-8')
    
    print("\n‚úÖ Parche aplicado exitosamente!")
    print("\nüìã Cambios realizados:")
    print("   ‚Ä¢ A√±adida importaci√≥n del detector de programaci√≥n")
    print("   ‚Ä¢ Reemplazado RAGParallelFetcher con ProgrammingRAGFetcher")
    print("   ‚Ä¢ Actualizadas secciones de detecci√≥n y manejo de RAG")
    print("   ‚Ä¢ Ahora el RAG solo se activar√° para consultas de programaci√≥n")
    
    return True

def create_instruction_file():
    """Crear archivo con instrucciones para activar el parche"""
    
    instructions = '''# Activaci√≥n del Sistema RAG Solo para Programaci√≥n

## Descripci√≥n
El sistema ha sido actualizado para que el RAG (Retrieval Augmented Generation) 
solo se active para consultas relacionadas con programaci√≥n, no para cualquier 
tipo de conocimiento general.

## Funcionamiento
- El detector ahora identifica expl√≠citamente consultas de programaci√≥n
- Solo se activa RAG para consultas que involucren:
  * C√≥digo en lenguajes de programaci√≥n
  * Sintaxis y sem√°ntica de lenguajes
  * Algoritmos e implementaciones
  * Depuraci√≥n y resoluci√≥n de errores
  * Documentaci√≥n de APIs y bibliotecas
  * Frameworks y herramientas de desarrollo

## Archivos Actualizados
- `livemind_orchestrator.py`: Actualizado para usar ProgrammingRAGFetcher
- `programming_rag_detector.py`: Nuevo detector espec√≠fico para programaci√≥n

## Validaci√≥n
Para validar el funcionamiento, se puede probar con:

1. Consultas de programaci√≥n (deben activar RAG):
   - "¬øC√≥mo implemento un algoritmo de ordenamiento en Python?"
   - "Necesito ayuda con un error en mi c√≥digo JavaScript"
   - "Muestra un ejemplo de conexi√≥n a base de datos en Java"

2. Consultas generales (NO deben activar RAG):
   - "¬øCu√°l es la capital de Francia?"
   - "Expl√≠came la teor√≠a de la relatividad"
   - "¬øC√≥mo cocinar una tortilla espa√±ola?"

## Beneficios
- Menor latencia para consultas no t√©cnicas
- Uso m√°s eficiente de recursos
- Mejor enfoque en casos de uso espec√≠ficos de programaci√≥n
'''
    
    instruction_file = Path("/home/elect/capibara6/ACTIVATE_PROGRAMMING_ONLY_RAG.md")
    instruction_file.write_text(instructions, encoding='utf-8')
    
    print(f"\nüìÑ Instrucciones guardadas en: {instruction_file}")

if __name__ == "__main__":
    print("üîß Aplicando parche para RAG exclusivo para programaci√≥n")
    print("=" * 60)
    
    success = patch_livemind_orchestrator()
    
    if success:
        create_instruction_file()
        print(f"\nüéâ ¬°√âxito! El parche ha sido aplicado correctamente.")
        print("   El sistema RAG ahora solo se activar√° para consultas de programaci√≥n.")
    else:
        print(f"\n‚ùå Fall√≥ la aplicaci√≥n del parche.")