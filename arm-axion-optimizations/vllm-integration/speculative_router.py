"""
Speculative Routing for vLLM Multi-Expert System
Optimized for ARM Axion

Provides:
- Speculative generation start (before routing is complete)
- Abort and restart if routing prediction changes
- Early confidence detection for fast queries

Expected impact:
- TTFT -20-30% on high-confidence queries (obvious domain)
- No overhead on low-confidence queries (waits for routing)
- Small penalty (~5-10%) on queries that need route correction
"""

import sys
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import asyncio
import time
from dataclasses import dataclass

sys.path.insert(0, str(Path(__file__).parent.parent))


@dataclass
class SpeculativeDecision:
    """Decision about speculative execution"""
    should_speculate: bool
    expert_id: str
    confidence: float
    reason: str  # 'high_confidence_first_chunk', 'fast_classifier_hint', 'wait_for_routing'


class SpeculativeRouter:
    """
    Speculative routing manager

    Strategy:
    1. If first chunk gives high confidence (>0.85): START generation immediately
    2. Continue routing in parallel
    3. If routing changes: Abort and restart (small penalty)
    4. If routing confirms: Continue streaming (big win!)
    5. If low confidence (<0.85): Wait for routing (no speculation)

    Trade-offs:
    - High confidence queries: -30% TTFT (speculate correctly)
    - Medium confidence queries: Wait for routing (no change)
    - Misrouted queries: +5-10% latency (abort + restart penalty)

    Expected win rate: 70-80% of queries have high confidence on first chunk
    Expected net improvement: ~20-25% TTFT reduction overall
    """

    def __init__(
        self,
        speculation_threshold: float = 0.85,
        enable_speculation: bool = True,
        max_speculation_time: float = 0.5  # Max time to wait for routing confirmation
    ):
        """
        Initialize speculative router

        Args:
            speculation_threshold: Confidence threshold to start speculation
            enable_speculation: Enable speculative execution
            max_speculation_time: Max time to wait before committing to speculative route
        """
        self.speculation_threshold = speculation_threshold
        self.enable_speculation = enable_speculation
        self.max_speculation_time = max_speculation_time

        # Stats
        self.total_decisions = 0
        self.speculated = 0
        self.speculate_correct = 0
        self.speculate_incorrect = 0
        self.speculation_time_saved = []

        print(f"‚úÖ Speculative Router initialized")
        print(f"   Enabled: {enable_speculation}")
        print(f"   Threshold: {speculation_threshold}")

    def decide_speculation(
        self,
        first_chunk_confidence: float,
        first_chunk_expert: str,
        fast_classifier_hint: Optional[Tuple[str, float]] = None
    ) -> SpeculativeDecision:
        """
        Decide whether to speculate

        Args:
            first_chunk_confidence: Confidence from first chunk routing
            first_chunk_expert: Predicted expert from first chunk
            fast_classifier_hint: Optional hint from fast classifier (expert_id, confidence)

        Returns:
            Speculation decision
        """
        self.total_decisions += 1

        if not self.enable_speculation:
            return SpeculativeDecision(
                should_speculate=False,
                expert_id=first_chunk_expert,
                confidence=first_chunk_confidence,
                reason='speculation_disabled'
            )

        # Strategy 1: High confidence from first chunk
        if first_chunk_confidence >= self.speculation_threshold:
            self.speculated += 1
            return SpeculativeDecision(
                should_speculate=True,
                expert_id=first_chunk_expert,
                confidence=first_chunk_confidence,
                reason='high_confidence_first_chunk'
            )

        # Strategy 2: Fast classifier gives strong hint
        if fast_classifier_hint:
            hint_expert, hint_confidence = fast_classifier_hint
            if hint_confidence >= self.speculation_threshold:
                # Check if fast classifier agrees with first chunk
                if hint_expert == first_chunk_expert:
                    self.speculated += 1
                    return SpeculativeDecision(
                        should_speculate=True,
                        expert_id=hint_expert,
                        confidence=hint_confidence,
                        reason='fast_classifier_hint'
                    )

        # Default: Wait for routing
        return SpeculativeDecision(
            should_speculate=False,
            expert_id=first_chunk_expert,
            confidence=first_chunk_confidence,
            reason='wait_for_routing'
        )

    def record_speculation_result(
        self,
        was_correct: bool,
        time_saved: Optional[float] = None
    ):
        """
        Record result of speculation

        Args:
            was_correct: Whether speculation chose correct expert
            time_saved: Time saved by speculation (negative if incorrect)
        """
        if was_correct:
            self.speculate_correct += 1
            if time_saved is not None and time_saved > 0:
                self.speculation_time_saved.append(time_saved)
        else:
            self.speculate_incorrect += 1
            # Penalty for incorrect speculation (abort + restart cost)
            if time_saved is not None:
                self.speculation_time_saved.append(time_saved)  # Will be negative

    def get_stats(self) -> Dict[str, Any]:
        """Get speculation statistics"""
        stats = {
            'total_decisions': self.total_decisions,
            'speculated': self.speculated,
            'speculation_rate': f"{(self.speculated / self.total_decisions * 100):.1f}%" if self.total_decisions > 0 else "0%",
            'speculate_correct': self.speculate_correct,
            'speculate_incorrect': self.speculate_incorrect,
            'accuracy': f"{(self.speculate_correct / self.speculated * 100):.1f}%" if self.speculated > 0 else "0%"
        }

        if self.speculation_time_saved:
            import numpy as np
            stats['time_saved'] = {
                'mean': np.mean(self.speculation_time_saved),
                'median': np.median(self.speculation_time_saved),
                'total': sum(self.speculation_time_saved)
            }

        return stats


async def speculative_generate_with_routing(
    request_id: str,
    prompt: str,
    router,
    chunker,
    expert_system,
    speculative_router: SpeculativeRouter,
    fast_classifier = None,
    sampling_params = None
) -> Tuple[str, Dict[str, Any]]:
    """
    Generate with speculative routing

    Workflow:
    1. Process first chunk
    2. Decide if we should speculate
    3. If yes: Start generation + continue routing in parallel
    4. If routing changes: Abort and restart
    5. If routing confirms: Return speculative results

    Args:
        request_id: Request ID
        prompt: User prompt
        router: Semantic router
        chunker: Text chunker
        expert_system: Multi-expert system
        speculative_router: Speculative router
        fast_classifier: Optional fast classifier
        sampling_params: vLLM sampling params

    Returns:
        Tuple of (generated_text, metadata)
    """
    start_time = time.time()

    # Phase 1: Process first chunk
    chunks = chunker.chunk_text(prompt)
    if not chunks:
        raise ValueError("No chunks generated from prompt")

    first_chunk = chunks[0]

    # Get fast classifier hint
    fast_hint = None
    if fast_classifier:
        domain, confidence = fast_classifier.classify(first_chunk.text)
        fast_hint = (domain, confidence)

    # Process first chunk routing
    routing_pred = router.process_chunk(request_id, first_chunk.text)

    # Phase 2: Decide speculation
    speculation_decision = speculative_router.decide_speculation(
        first_chunk_confidence=routing_pred.confidence,
        first_chunk_expert=routing_pred.expert_ids[0] if routing_pred.expert_ids else "default",
        fast_classifier_hint=fast_hint
    )

    print(f"üé≤ [{request_id}] Speculation: {speculation_decision.should_speculate} ({speculation_decision.reason}, conf: {speculation_decision.confidence:.2f})")

    if not speculation_decision.should_speculate:
        # No speculation: Continue routing normally
        for i, chunk in enumerate(chunks[1:], 1):
            routing_pred = router.process_chunk(request_id, chunk.text)
            if routing_pred.can_route:
                break

        if not routing_pred.can_route:
            routing_pred = router.finalize_routing(request_id)

        # Generate from final routed expert
        expert = await expert_system.get_expert(routing_pred.expert_ids[0])
        result = expert.generate([prompt], sampling_params)[0]

        return result['text'], {
            'speculated': False,
            'expert_id': routing_pred.expert_ids[0],
            'ttft': time.time() - start_time
        }

    # Phase 3: Speculative execution
    # Start generation from speculative expert
    speculative_expert_id = speculation_decision.expert_id
    print(f"üöÄ [{request_id}] Starting speculative generation from: {speculative_expert_id}")

    # Create async tasks
    spec_gen_task = asyncio.create_task(
        asyncio.to_thread(
            lambda: expert_system.get_expert_sync(speculative_expert_id).generate([prompt], sampling_params)[0]
        )
    )

    # Continue routing in parallel
    routing_changed = False
    final_expert_id = speculative_expert_id

    for i, chunk in enumerate(chunks[1:], 1):
        routing_pred = router.process_chunk(request_id, chunk.text)

        # Check if routing changed
        if routing_pred.can_route:
            final_expert_id = routing_pred.expert_ids[0]
            if final_expert_id != speculative_expert_id:
                routing_changed = True
                print(f"‚ö†Ô∏è  [{request_id}] Routing changed: {speculative_expert_id} -> {final_expert_id}")
                break

    if not routing_pred.can_route:
        routing_pred = router.finalize_routing(request_id)
        final_expert_id = routing_pred.expert_ids[0]
        if final_expert_id != speculative_expert_id:
            routing_changed = True

    # Phase 4: Handle speculation result
    speculation_time = time.time() - start_time

    if routing_changed:
        # Abort speculative generation (cancel task if still running)
        spec_gen_task.cancel()
        print(f"‚ùå [{request_id}] Speculation incorrect, restarting with: {final_expert_id}")

        # Restart with correct expert
        correct_expert = await expert_system.get_expert(final_expert_id)
        result = correct_expert.generate([prompt], sampling_params)[0]

        # Record failure (time penalty)
        time_penalty = -(time.time() - start_time - speculation_time)
        speculative_router.record_speculation_result(False, time_penalty)

        return result['text'], {
            'speculated': True,
            'speculation_correct': False,
            'expert_id': final_expert_id,
            'speculative_expert_id': speculative_expert_id,
            'ttft': time.time() - start_time
        }

    else:
        # Speculation correct! Use speculative results
        spec_result = await spec_gen_task
        print(f"‚úÖ [{request_id}] Speculation correct! Expert: {speculative_expert_id}")

        # Record success (time saved)
        time_saved = speculation_time * 0.3  # Estimate: 30% time saved by early start
        speculative_router.record_speculation_result(True, time_saved)

        return spec_result['text'], {
            'speculated': True,
            'speculation_correct': True,
            'expert_id': speculative_expert_id,
            'ttft': speculation_time,
            'time_saved': time_saved
        }


if __name__ == '__main__':
    print("üß™ Testing Speculative Router")
    print("=" * 60)

    # Test speculation decisions
    router = SpeculativeRouter(
        speculation_threshold=0.85,
        enable_speculation=True
    )

    test_cases = [
        ("high confidence", 0.92, "expert_general", None, True),
        ("medium confidence", 0.70, "expert_technical", None, False),
        ("low confidence", 0.45, "expert_general", None, False),
        ("fast classifier boost", 0.75, "expert_technical", ("expert_technical", 0.90), True),
    ]

    print("\nüìù Testing Speculation Decisions:")
    for name, confidence, expert, hint, expected_speculate in test_cases:
        decision = router.decide_speculation(confidence, expert, hint)
        match = "‚úÖ" if decision.should_speculate == expected_speculate else "‚ùå"
        print(f"{match} {name}:")
        print(f"   Should speculate: {decision.should_speculate}")
        print(f"   Expert: {decision.expert_id}")
        print(f"   Confidence: {decision.confidence:.2f}")
        print(f"   Reason: {decision.reason}")

    # Simulate some results
    print("\nüìù Simulating Speculation Results:")
    router.record_speculation_result(True, 0.15)  # Correct, saved 150ms
    router.record_speculation_result(True, 0.12)  # Correct, saved 120ms
    router.record_speculation_result(False, -0.05)  # Incorrect, penalty 50ms
    router.record_speculation_result(True, 0.18)  # Correct, saved 180ms

    # Get stats
    print(f"\nüìä Speculation Stats:")
    stats = router.get_stats()
    for key, value in stats.items():
        print(f"   {key}: {value}")
