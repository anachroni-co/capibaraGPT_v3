# capibara/sub_models - Sub-Models Architecture

El directorio **sub_models** contiene todos los sub-modelos especializados que pueden ser combinados modularmente para construir arquitecturas personalizadas.

## ğŸ“‹ Tabla de Contenidos

1. [VisiÃ³n General](#visiÃ³n-general)
2. [Sub-Modelos Disponibles](#sub-modelos-disponibles)
3. [Arquitectura Modular](#arquitectura-modular)
4. [Quick Start](#quick-start)
5. [Sub-Modelos Detallados](#sub-modelos-detallados)
6. [IntegraciÃ³n y ComposiciÃ³n](#integraciÃ³n-y-composiciÃ³n)
7. [Performance Comparison](#performance-comparison)

---

## ğŸ¯ VisiÃ³n General

capibaraGPT-v2 usa una **arquitectura completamente modular** donde diferentes sub-modelos pueden ser combinados segÃºn las necesidades:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ModularCapibaraModel                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚   â”‚   Mamba     â”‚â”€â”€â”€â”€>â”‚ Hybrid Routerâ”‚                  â”‚
â”‚   â”‚   (SSM)     â”‚     â”‚              â”‚                  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                              â”‚                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ Transformer â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€>â”‚    Vision    â”‚    â”‚
â”‚   â”‚             â”‚                    â”‚   Encoder    â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚   â”‚   Semiotic   â”‚    â”‚ Deep Dialog  â”‚                  â”‚
â”‚   â”‚  Grounding   â”‚    â”‚ Reasoning    â”‚                  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### FilosofÃ­a de DiseÃ±o

- **Modular**: Cada sub-modelo puede usarse independientemente
- **Composable**: Combinar mÃºltiples sub-modelos fÃ¡cilmente
- **Optimized**: Cada sub-modelo optimizado para su tarea especÃ­fica
- **Flexible**: Intercambiar sub-modelos sin cambiar arquitectura general

---

## ğŸ§© Sub-Modelos Disponibles

| Sub-Modelo | Directorio | PropÃ³sito | DocumentaciÃ³n |
|------------|-----------|-----------|---------------|
| **Mamba (SSM)** | `mamba/` | AtenciÃ³n O(n) para secuencias largas | [README](mamba/README.md) |
| **Hybrid Attention** | `hybrid/` | Router Mamba/Transformer inteligente | [README](hybrid/README.md) |
| **Vision** | `vision/` | Encoder de imÃ¡genes/video | - |
| **Semiotic** | `semiotic/` | Grounding semiÃ³tico y simbÃ³lico | - |
| **Deep Dialog** | `deep_dialog.py` | DiÃ¡logo multi-turno avanzado | - |
| **CSA Expert** | `csa_expert.py` | Cross-Stream Attention expert | - |
| **Reasoning Enhancement** | `reasoning_enhancement.py` | Mejoras de razonamiento | - |
| **Byte-Level** | `Byte_TPU.py` | Procesamiento byte-level | - |
| **Experimental** | `experimental/` | Sub-modelos experimentales | - |
| **Capibaras** | `capibaras/` | Variantes del modelo Capibara | - |

---

## ğŸ—ï¸ Arquitectura Modular

### ModularCapibaraModel

El modelo principal integra todos los sub-modelos:

```python
from capibara.core import ModularCapibaraModel, ModularConfig
from capibara.sub_models import (
    MambaModule,
    HybridAttentionModule,
    VisionEncoder,
    SemioticGrounder
)

# Configurar mÃ³dulos
config = ModularConfig(
    # Base model
    hidden_size=768,
    num_layers=12,

    # Sub-models activos
    use_mamba=True,
    use_hybrid_attention=True,
    use_vision_encoder=True,
    use_semiotic=True,

    # Sub-model configs
    mamba_config=MambaConfig(...),
    vision_config=VisionConfig(...)
)

# Crear modelo modular
model = ModularCapibaraModel(config)

# El modelo usa automÃ¡ticamente los sub-modelos configurados
output = model(inputs)
```

### Orquestador de Sub-Modelos

```python
from capibara.sub_models import UltraSubmodelOrchestrator

# Crear orquestador
orchestrator = UltraSubmodelOrchestrator(
    enabled_submodels=[
        "mamba",
        "hybrid_attention",
        "deep_dialog",
        "reasoning_enhancement"
    ]
)

# Orquestar ejecuciÃ³n
result = orchestrator.process(
    inputs=inputs,
    task_type="reasoning"  # reasoning, dialog, vision, etc.
)

# El orquestrador selecciona automÃ¡ticamente los sub-modelos apropiados
```

---

## ğŸš€ Quick Start

### Uso BÃ¡sico: Mamba

```python
from capibara.sub_models.mamba import MambaModule, MambaConfig

# Configurar Mamba
config = MambaConfig(
    hidden_size=768,
    d_state=16,
    d_conv=4,
    expand_factor=2
)

# Crear mÃ³dulo
mamba = MambaModule(config)

# Forward pass
import jax.numpy as jnp
inputs = jnp.ones((2, 512, 768))  # (batch, seq_len, hidden)
outputs = mamba(inputs)

# Complejidad: O(n) vs O(nÂ²) de Transformer
```

### Uso BÃ¡sico: Hybrid Attention

```python
from capibara.sub_models.hybrid import HybridAttentionModule

# Configurar router hÃ­brido
hybrid = HybridAttentionModule(
    config={
        "mamba_threshold": 512,
        "use_dynamic_routing": True
    }
)

# Routing automÃ¡tico
outputs = hybrid(inputs)  # Usa Mamba si seq_len >= 512, sino Transformer

# Inspeccionar decisiÃ³n
print(f"Used: {hybrid.last_decision}")  # "mamba" o "transformer"
```

### Uso BÃ¡sico: Vision

```python
from capibara.sub_models.vision import VisionEncoder

# Configurar vision encoder
vision = VisionEncoder(
    hidden_size=768,
    image_size=224,
    patch_size=16
)

# Encodear imagen
image = jnp.ones((1, 224, 224, 3))  # (batch, H, W, C)
image_embeddings = vision(image)  # (batch, num_patches, hidden_size)

# Combinar con texto
combined = model.combine_modalities(
    text_emb=text_embeddings,
    vision_emb=image_embeddings
)
```

---

## ğŸ”§ Sub-Modelos Detallados

### 1. Mamba (Selective State Space Model)

**PropÃ³sito**: AtenciÃ³n eficiente O(n) para secuencias largas

```python
from capibara.sub_models.mamba import MambaModule

mamba = MambaModule(config)

# CaracterÃ­sticas:
# - Complejidad: O(n) vs O(nÂ²) Transformer
# - Ideal para: Secuencias > 512 tokens
# - TPU optimizado: Scan asociativo
# - Memory efficient: ~50% menos memoria que Transformer
```

Ver [mamba/README.md](mamba/README.md) para documentaciÃ³n completa.

### 2. Hybrid Attention

**PropÃ³sito**: Router inteligente entre Mamba y Transformer

```python
from capibara.sub_models.hybrid import HybridAttentionModule

hybrid = HybridAttentionModule(
    mamba_threshold=512,
    use_dynamic_routing=True,
    memory_threshold=0.8
)

# DecisiÃ³n basada en:
# - Longitud de secuencia
# - Memoria disponible
# - Requerimientos de latencia
# - Calidad requerida
```

Ver [hybrid/README.md](hybrid/README.md) para documentaciÃ³n completa.

### 3. Vision Encoder

**PropÃ³sito**: Procesar imÃ¡genes y video

```python
from capibara.sub_models.vision import VisionEncoder, VideoEncoder

# ImÃ¡genes
vision = VisionEncoder(
    architecture="vit",  # vit, resnet, convnext
    pretrained="imagenet"
)

# Video
video = VideoEncoder(
    num_frames=16,
    temporal_pooling="attention"
)

# Multimodal fusion
from capibara.core.encoders import MultimodalCombiner
combiner = MultimodalCombiner(fusion_type="cross_attention")
fused = combiner(text=text_emb, vision=vision_emb)
```

### 4. Semiotic Grounding

**PropÃ³sito**: Grounding semiÃ³tico y simbÃ³lico

```python
from capibara.sub_models.semiotic import SemioticGrounder

semiotic = SemioticGrounder(
    symbol_vocab_size=10000,
    grounding_layers=4
)

# Grounding de sÃ­mbolos a conceptos
grounded = semiotic.ground(
    symbols=["apple", "red", "fruit"],
    context=text_context
)

# Reasoning simbÃ³lico
reasoning_result = semiotic.reason(
    premises=["All apples are fruits", "This is an apple"],
    query="Is this a fruit?"
)
```

### 5. Deep Dialog

**PropÃ³sito**: DiÃ¡logo multi-turno con memoria de contexto

```python
from capibara.sub_models import DeepDialogModel

dialog = DeepDialogModel(
    max_context_length=4096,
    use_episodic_memory=True
)

# ConversaciÃ³n multi-turno
context = dialog.initialize_context()

for user_input in conversation:
    response = dialog.respond(
        user_input=user_input,
        context=context
    )
    context = dialog.update_context(context, user_input, response)
```

### 6. CSA Expert (Cross-Stream Attention)

**PropÃ³sito**: AtenciÃ³n cruzada entre mÃºltiples streams de informaciÃ³n

```python
from capibara.sub_models import CSAExpert

csa = CSAExpert(
    num_streams=3,  # text, vision, audio
    cross_attention_heads=12
)

# Procesar mÃºltiples streams
outputs = csa.process_streams(
    text_stream=text,
    vision_stream=images,
    audio_stream=audio
)

# Cross-stream attention automÃ¡tica
```

### 7. Reasoning Enhancement

**PropÃ³sito**: Mejoras especÃ­ficas para razonamiento

```python
from capibara.sub_models import ReasoningEnhancement

reasoning = ReasoningEnhancement(
    use_scratch_pad=True,
    use_self_consistency=True,
    num_reasoning_paths=5
)

# Razonamiento mejorado
result = reasoning.reason(
    problem="Si Juan tiene 5 manzanas y le da 2 a MarÃ­a...",
    reasoning_type="mathematical"
)

# Incluye:
# - Scratch pad para trabajo intermedio
# - Self-consistency voting
# - Multiple reasoning paths
```

### 8. Byte-Level Processing (TPU Optimized)

**PropÃ³sito**: Procesamiento a nivel de bytes

```python
from capibara.sub_models import ByteTPU

byte_model = ByteTPU(
    vocab_size=256,  # 256 bytes posibles
    use_tpu_optimizations=True
)

# Procesar bytes directamente (sin tokenizaciÃ³n)
byte_inputs = jnp.array([72, 101, 108, 108, 111])  # "Hello"
outputs = byte_model(byte_inputs)

# Ventajas:
# - No necesita tokenizer
# - Maneja cualquier idioma/script
# - Robusto a errores de ortografÃ­a
```

---

## ğŸ”— IntegraciÃ³n y ComposiciÃ³n

### ComposiciÃ³n Manual

```python
from capibara.sub_models import (
    MambaModule,
    VisionEncoder,
    DeepDialogModel,
    ReasoningEnhancement
)

class MyCustomModel:
    def __init__(self, config):
        # Combinar sub-modelos manualmente
        self.mamba = MambaModule(config.mamba_config)
        self.vision = VisionEncoder(config.vision_config)
        self.dialog = DeepDialogModel(config.dialog_config)
        self.reasoning = ReasoningEnhancement(config.reasoning_config)

    def __call__(self, inputs, images=None, context=None):
        # 1. Vision encoding (si hay imÃ¡genes)
        if images is not None:
            vision_emb = self.vision(images)
            inputs = self.combine(inputs, vision_emb)

        # 2. Mamba processing
        mamba_output = self.mamba(inputs)

        # 3. Dialog context
        if context is not None:
            mamba_output = self.dialog.apply_context(mamba_output, context)

        # 4. Reasoning enhancement
        final_output = self.reasoning.enhance(mamba_output)

        return final_output
```

### ComposiciÃ³n con Orquestador

```python
from capibara.sub_models import UltraSubmodelOrchestrator

# El orquestador maneja la composiciÃ³n automÃ¡ticamente
orchestrator = UltraSubmodelOrchestrator(
    enabled_submodels=["mamba", "vision", "dialog", "reasoning"]
)

# Detecta automÃ¡ticamente quÃ© sub-modelos usar segÃºn inputs
output = orchestrator.process(
    text=text_input,
    images=images,  # Activa vision automÃ¡ticamente
    task="reasoning"  # Activa reasoning automÃ¡ticamente
)
```

### IntegraciÃ³n con ModularCapibaraModel

```python
from capibara.core import ModularCapibaraModel, ModularConfig

config = ModularConfig(
    # Configurar todos los sub-modelos
    use_mamba=True,
    mamba_config=MambaConfig(...),

    use_vision=True,
    vision_config=VisionConfig(...),

    use_dialog=True,
    dialog_config=DialogConfig(...),

    use_reasoning=True,
    reasoning_config=ReasoningConfig(...)
)

# Modelo integra automÃ¡ticamente todos los sub-modelos
model = ModularCapibaraModel(config)

# Uso unificado
output = model(
    text_inputs=text,
    image_inputs=images,
    dialog_context=context
)
```

---

## ğŸ“Š Performance Comparison

### Latency (512 tokens, batch_size=1)

| Sub-Model | Latency | Memory | Throughput |
|-----------|---------|--------|------------|
| Mamba | 45ms | 2GB | 1200 req/s |
| Transformer | 120ms | 4GB | 450 req/s |
| Hybrid (auto) | 50-110ms | 2-3.5GB | 900 req/s |
| Vision | 30ms | 1.5GB | 1500 req/s |
| Deep Dialog | 60ms | 2.5GB | 800 req/s |

### Complejidad Computacional

| Sub-Model | Time Complexity | Space Complexity |
|-----------|----------------|------------------|
| Mamba | O(n) | O(n) |
| Transformer | O(nÂ²) | O(nÂ²) |
| Hybrid | O(n) - O(nÂ²) | O(n) - O(nÂ²) |
| Vision (ViT) | O(nÂ²) patches | O(nÂ²) |
| CSA Expert | O(nÂ²) per stream | O(nÂ²) |

### Cuando Usar Cada Sub-Modelo

| Caso de Uso | Sub-Modelo Recomendado | RazÃ³n |
|-------------|------------------------|-------|
| Secuencias > 1024 tokens | Mamba | O(n) complexity |
| Secuencias < 512 tokens | Transformer | Mejor calidad |
| Secuencias variables | Hybrid Attention | Adaptativo |
| Multimodal (texto + imagen) | Vision + Mamba | Eficiente multimodal |
| DiÃ¡logo multi-turno | Deep Dialog | Memoria contextual |
| Razonamiento complejo | Reasoning Enhancement | Multiple paths |
| MÃºltiples fuentes de datos | CSA Expert | Cross-stream attention |

---

## ğŸ› ï¸ Desarrollo de Nuevos Sub-Modelos

### Template para Nuevo Sub-Modelo

```python
from flax import linen as nn
from capibara.core.interfaces import IModule
from typing import Any, Dict

class MyNewSubModel(nn.Module, IModule):
    """Mi nuevo sub-modelo personalizado."""

    hidden_size: int
    custom_param: float = 1.0

    def setup(self):
        """Inicializar componentes."""
        self.layer1 = nn.Dense(self.hidden_size)
        self.layer2 = nn.Dense(self.hidden_size)

    def __call__(self, inputs, **kwargs):
        """Forward pass."""
        x = self.layer1(inputs)
        x = nn.relu(x)
        x = self.layer2(x)
        return x

    def get_metrics(self) -> Dict[str, Any]:
        """MÃ©tricas del mÃ³dulo."""
        return {
            "module_type": "MyNewSubModel",
            "hidden_size": self.hidden_size,
            "custom_param": self.custom_param
        }

    def get_config(self) -> Dict[str, Any]:
        """ConfiguraciÃ³n del mÃ³dulo."""
        return {
            "hidden_size": self.hidden_size,
            "custom_param": self.custom_param
        }
```

### Registrar en ModularCapibaraModel

```python
# En capibara/core/modular_model.py
from capibara.sub_models.my_new import MyNewSubModel

class ModularCapibaraModel(nn.Module):
    def setup(self):
        # ...existing setup...

        # Agregar nuevo sub-modelo
        if self.config.use_my_new:
            self.my_new = MyNewSubModel(
                hidden_size=self.config.hidden_size,
                **self.config.my_new_config
            )
```

---

## ğŸ“š Referencias

- [Mamba Module](mamba/README.md) - DocumentaciÃ³n completa Mamba
- [Hybrid Attention](hybrid/README.md) - DocumentaciÃ³n Hybrid Router
- [Core Integration](../core/README.md) - IntegraciÃ³n con core
- [ModularCapibaraModel](../core/modular_model.py) - Modelo modular principal

---

## ğŸ†˜ Troubleshooting

### Error: "Sub-model not found"

```python
# Verificar sub-modelos disponibles
from capibara.sub_models import list_available_submodels

available = list_available_submodels()
print(f"Available: {available}")
```

### Error: "Incompatible dimensions"

Asegurar que todos los sub-modelos usan el mismo `hidden_size`:

```python
config = ModularConfig(
    hidden_size=768,  # Mismo para todos
    mamba_config=MambaConfig(hidden_size=768),
    vision_config=VisionConfig(output_size=768)
)
```

### Performance Lento

- Usar Mamba para secuencias largas
- Usar Hybrid Attention para adaptaciÃ³n automÃ¡tica
- Habilitar TPU optimizations en configs
- Usar cuantizaciÃ³n para inferencia

---

**Ãšltima actualizaciÃ³n**: 2025-11-16
**VersiÃ³n del sistema**: v2.0.0
