#!/usr/bin/env python3
"""
Prueba de concepto: Consenso por turnos ARM-Axion
Simulando mÃºltiples modelos especialistas que responden en secuencia
"""

import requests
import time
import json
import psutil
from typing import Dict, List

def get_ram_usage_percent():
    """Obtiene el porcentaje de uso de RAM"""
    return psutil.virtual_memory().percent

def simulate_turn_based_consensus():
    """
    Simula un sistema de consenso por turnos con modelos especialistas
    """
    print("ğŸš€ SIMULACIÃ“N DE CONSENSO POR TURNOS ARM-Axion")
    print("="*70)
    print("Pregunta: Â¿Puede el ser humano ser completamente reemplazado por las nuevas IAS y")
    print("por los robots inteligentes en los prÃ³ximos 20 aÃ±os? Â¿QuÃ© probabilidades hay?")
    print("="*70)
    
    ram_initial = get_ram_usage_percent()
    print(f"ğŸ“Š RAM inicial: {ram_initial:.1f}%")
    
    # La pregunta principal
    main_question = "Â¿Puede el ser humano ser completamente reemplazado por las nuevas IAS y por los robots inteligentes en los prÃ³ximos 20 aÃ±os? Â¿QuÃ© probabilidades hay?"
    
    # Definir perspectivas por modelo especialista
    specialist_questions = {
        "phi4_fast": f"[VisiÃ³n General] {main_question} Da una respuesta general concisa.",
        "mistral_balanced": f"[AnÃ¡lisis TÃ©cnico] {main_question} Considera capacidades y limitaciones tÃ©cnicas actuales.",
        "qwen_coder": f"[Perspectiva de IngenierÃ­a] {main_question} Considera aspectos de desarrollo tecnolÃ³gico y automatizaciÃ³n.",
        "aya_expanse_multilingual": f"[Perspectiva Global] {main_question} Considera aspectos culturales, Ã©ticos y sociales internacionales."
    }
    
    # Resultados del consenso por turnos
    turn_results = {}
    total_time = 0
    total_tokens = 0
    
    print(f"\\nğŸ”„ INICIANDO CONSENSO POR TURNOS...")
    print("-" * 70)
    
    for idx, (model, question) in enumerate(specialist_questions.items(), 1):
        print(f"\\nTURNO {idx}: {model.upper()}")
        print(f"   Pregunta: '{question[:50]}...'")
        
        # Verificar RAM antes de cada turno
        ram_before = get_ram_usage_percent()
        print(f"   ğŸ“Š RAM antes: {ram_before:.1f}%")
        
        if ram_before > 95.0:
            print(f"   âš ï¸  RAM muy alta, abortando turno {idx}")
            continue
            
        start_time = time.time()
        
        try:
            # Intentar usar el modelo disponible
            response = requests.post(
                "http://localhost:8082/v1/chat/completions",  # Servidor estÃ¡ndar
                json={
                    "model": model,
                    "messages": [
                        {"role": "user", "content": question}
                    ],
                    "max_tokens": 40,  # Limitar para seguridad RAM
                    "temperature": 0.7
                },
                timeout=60
            )
            
            turn_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                tokens = result['usage']['completion_tokens']
                
                turn_results[model] = {
                    "response": content,
                    "tokens": tokens,
                    "time": turn_time,
                    "speed": tokens / turn_time if turn_time > 0 else 0
                }
                
                total_time += turn_time
                total_tokens += tokens
                
                print(f"   âœ… Ã‰xito: {turn_time:.2f}s ({tokens} tokens, {tokens/turn_time:.2f} tok/s)")
                print(f"   ğŸ“„ Resumen: {content[:80]}...")
            else:
                print(f"   âŒ HTTP {response.status_code}")
                
        except Exception as e:
            print(f"   âŒ Error en turno {idx}: {e}")
        
        ram_after = get_ram_usage_percent()
        print(f"   ğŸ“Š RAM despuÃ©s: {ram_after:.1f}% (+{ram_after-ram_before:+.1f}%)")
        
        # PequeÃ±o delay entre turnos para no sobrecargar
        time.sleep(1)
    
    print("\\n" + "="*70)
    print("ğŸ“Š RESULTADOS DEL CONSENSO POR TURNOS")
    print("="*70)
    
    if turn_results:
        print(f"â±ï¸  Tiempo total: {total_time:.2f}s")
        print(f"ğŸ”¢ Tokens totales: {total_tokens}")
        print(f"âš¡ Velocidad promedio: {total_tokens/total_time:.2f} tokens/segundo")
        print(f"ğŸ‘¥ Modelos participantes: {len(turn_results)}")
        
        print("\\nğŸ“ PERSPECTIVAS POR ESPECIALISTA:")
        print("-" * 70)
        
        for model, data in turn_results.items():
            print(f"\\nğŸ”¹ {model.upper()}:")
            print(f"   DuraciÃ³n: {data['time']:.2f}s | Tokens: {data['tokens']} | Vel.: {data['speed']:.2f} tok/s")
            print(f"   Vista: {data['response'][:120]}...")
            
        print("\\nğŸ¯ SÃNTESIS DE CONSENSO:")
        print("-" * 70)
        
        # Crear una sÃ­ntesis de las perspectivas
        perspectives = []
        for model, data in turn_results.items():
            model_short = model.split('_')[0].upper()
            perspectives.append(f"- {model_short}: {data['response'][:60]}...")
        
        for perspective in perspectives:
            print(f"  {perspective}")
            
        print(f"\\nğŸ” CONCLUSIONES PRELIMINARES:")
        has_technical_limitations = any("limitaciÃ³n" in data["response"].lower() or "difÃ­cil" in data["response"].lower() 
                                       for data in turn_results.values())
        has_ethical_concerns = any("Ã©tico" in data["response"].lower() or "social" in data["response"].lower() 
                                  or "humano" in data["response"].lower())
        
        print(f"   â€¢ Â¿Reemplazo total es factible?: {'Posible pero con limitaciones' if has_technical_limitations else 'Potencialmente factible'}")
        print(f"   â€¢ Â¿Consideraciones Ã©ticas presentes?: {'SÃ­' if has_ethical_concerns else 'No evidentes aÃºn'}")
        print(f"   â€¢ Â¿Plazo de 20 aÃ±os razonable?: {'Variable segÃºn especialista' if len(turn_results) > 1 else 'Requiere mÃºltiples perspectivas'}")
        
    else:
        print("âŒ No se obtuvieron resultados de ningÃºn modelo")
    
    final_ram = get_ram_usage_percent()
    print(f"\\nğŸ“Š RAM final: {final_ram:.1f}% (cambio total: {final_ram - ram_initial:+.1f}%)")
    print("âœ… SimulaciÃ³n de consenso por turnos completada")


def main():
    """FunciÃ³n principal"""
    print("ğŸ¦« SimulaciÃ³n de Consenso por Turnos - Sistema ARM-Axion")
    print("   Evaluando mÃºltiples perspectivas con control de recursos")
    print("="*70)
    
    simulate_turn_based_consensus()


if __name__ == "__main__":
    main()