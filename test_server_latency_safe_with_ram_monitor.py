#!/usr/bin/env python3
"""
Versi√≥n segura de la prueba de latencia para cualquier servidor ARM-Axion
Monitoreo de RAM para prevenir bloqueos del servidor
"""

import requests
import time
import json
import psutil
import os
from typing import Dict, List, Optional
import statistics

def get_ram_usage_percent():
    """Obtiene el porcentaje de uso de RAM"""
    return psutil.virtual_memory().percent

def check_ram_usage(threshold: float = 90.0):
    """Verifica si el uso de RAM excede el umbral"""
    ram_percent = get_ram_usage_percent()
    if ram_percent > threshold:
        print(f"‚ö†Ô∏è  RAM uso: {ram_percent:.1f}% - SUPERIOR AL L√çMITE DE {threshold}%")
        return True
    else:
        print(f"üìä RAM uso: {ram_percent:.1f}% - Seguro para continuar")
        return False

def is_server_responding(url: str) -> bool:
    """Verifica si el servidor est√° respondiendo"""
    try:
        response = requests.get(f"{url}/health", timeout=10)
        return response.status_code == 200
    except:
        return False

def test_server_latency_safe(
    server_url: str = "http://localhost:8082",
    max_requests: int = 10,  # Reducido para ser m√°s seguro
    delay_between_requests: float = 3.0,
    ram_threshold: float = 90.0
):
    """
    Prueba de latencia segura que monitorea RAM para evitar bloqueos
    """
    print("üöÄ Iniciando prueba de latencia SEGURA...")
    print(f"   Servidor: {server_url}")
    print(f"   M√°ximo de solicitudes: {max_requests}")
    print(f"   Retraso entre solicitudes: {delay_between_requests}s")
    print(f"   L√≠mite de RAM: {ram_threshold}%")
    print("="*60)

    if not is_server_responding(server_url):
        print(f"‚ùå Servidor no responde en {server_url}")
        return

    # Test prompts para diferentes dominios
    test_prompts = [
        "¬øC√≥mo funciona la atenci√≥n Flash en ARM Axion?",
        "Explica brevemente el algoritmo de quicksort",
        "Escribe una funci√≥n en Python que calcule n√∫meros primos",
        "¬øCu√°l es la diferencia entre CPU e GPU para el procesamiento?",
        "Describe el concepto de optimizaci√≥n NEON en ARM"
    ]

    latencies = []
    tokens_per_second_values = []
    successful_requests = 0
    failed_requests = 0

    for i in range(max_requests):
        print(f"\\n--- Solicitud {i+1}/{max_requests} ---")
        
        # Verificar uso de RAM antes de cada solicitud
        if check_ram_usage(ram_threshold):
            print(f"‚ö†Ô∏è  Prueba detenida temprano por uso elevado de RAM")
            break
            
        # Verificar si el servidor sigue respondiendo
        if not is_server_responding(server_url):
            print(f"‚ùå Servidor dej√≥ de responder en solicitud {i+1}")
            failed_requests += 1
            break

        prompt = test_prompts[i % len(test_prompts)]
        print(f"üìù Prompt: '{prompt[:50]}...'")
        
        start_time = time.time()
        
        try:
            response = requests.post(
                f"{server_url}/v1/chat/completions",
                json={
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                    "max_tokens": 50,  # Reducido para ser m√°s seguro
                    "temperature": 0.7,
                    "model": ""  # Dejar vac√≠o para usar router autom√°tico (excepto en servidor b√°sico)
                },
                timeout=120  # Tiempo de espera m√°s largo
            )
            
            total_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                usage = result.get('usage', {})
                tokens_generated = usage.get('completion_tokens', 0)
                tokens_per_second = tokens_generated / total_time if total_time > 0 else 0
                
                latencies.append(total_time)
                tokens_per_second_values.append(tokens_per_second)
                successful_requests += 1
                
                print(f"‚úÖ √âxito: {total_time:.2f}s ({tokens_per_second:.2f} tok/s)")
                
                # Obtener modelo usado si est√° disponible
                model_used = result.get('model', 'unknown')
                if model_used != 'unknown':
                    print(f"   Modelo usado: {model_used}")
                
            else:
                print(f"‚ùå HTTP {response.status_code}: {str(response.text)[:100]}")
                failed_requests += 1
                
        except requests.exceptions.Timeout:
            print("‚è∞ Timeout")
            failed_requests += 1
        except requests.exceptions.RequestException as e:
            print(f"üí• Error de red: {e}")
            failed_requests += 1
        except Exception as e:
            print(f"üí• Error: {e}")
            failed_requests += 1

        # Verificar RAM despu√©s de la solicitud
        if check_ram_usage(ram_threshold):
            print(f"‚ö†Ô∏è  Prueba detenida por uso elevado de RAM despu√©s de solicitud {i+1}")
            break

        # Retraso entre solicitudes
        if i < max_requests - 1:  # No esperar despu√©s de la √∫ltima solicitud
            print(f"‚è≥ Esperando {delay_between_requests}s antes de siguiente solicitud...")
            time.sleep(delay_between_requests)

    # Resultados finales
    print("\\n" + "="*60)
    print("üìä RESULTADOS FINALES DE PRUEBA DE LATENCIA SEGURA")
    print("="*60)
    
    if latencies:
        print(f"‚úÖ Solicitudes exitosas: {successful_requests}")
        print(f"‚ùå Solicitudes fallidas: {failed_requests}")
        print(f"üìä Total de solicitudes intentadas: {successful_requests + failed_requests}")
        
        print(f"\\n‚è±Ô∏è  RENDIMIENTO:")
        if latencies:
            print(f"   Promedio latencia: {statistics.mean(latencies):.2f}s")
            print(f"   M√≠nimo latencia: {min(latencies):.2f}s")
            print(f"   M√°ximo latencia: {max(latencies):.2f}s")
            if len(latencies) > 1:
                print(f"   Desviaci√≥n est√°ndar: {statistics.stdev(latencies):.2f}s")
        
        if tokens_per_second_values:
            print(f"\\n‚ö° VELOCIDAD:")
            print(f"   Promedio tokens/seg: {statistics.mean(tokens_per_second_values):.2f}")
            print(f"   Rango: {min(tokens_per_second_values):.2f} - {max(tokens_per_second_values):.2f}")
        
        print(f"\\nüìà EFICIENCIA:")
        total_attempts = successful_requests + failed_requests
        if total_attempts > 0:
            print(f"   Tasa de √©xito: {(successful_requests/total_attempts*100):.1f}%")
    else:
        print("‚ùå No se completaron solicitudes exitosas")
    
    print(f"\\nüíæ RAM final: {get_ram_usage_percent():.1f}%")
    print("‚úÖ Prueba de latencia segura completada")


def main():
    """Funci√≥n principal con selecci√≥n de servidor"""
    print("ü¶´ Prueba Segura de Latencia - Sistema ARM-Axion")
    print("   Monitoreo de RAM para evitar bloqueos del servidor")
    print("   L√≠mite: 90% de uso de RAM")
    print("="*70)
    
    # Lista de servidores disponibles
    servers = {
        "1": ("http://localhost:8082", "Servidor Est√°ndar"),
        "2": ("http://localhost:8083", "Servidor con Streaming"), 
        "3": ("Seleccionar manualmente", "URL personalizada")
    }
    
    print("Selecciona un servidor para probar:")
    for key, (url, desc) in servers.items():
        print(f"  {key}. {desc} - {url}")
    
    choice = input("\\nIngresa tu elecci√≥n (1-3): ").strip()
    
    if choice == "1":
        server_url = "http://localhost:8082"
    elif choice == "2":
        server_url = "http://localhost:8083"
    elif choice == "3":
        server_url = input("Ingresa la URL del servidor (ej. http://localhost:8082): ").strip()
        if not server_url:
            server_url = "http://localhost:8082"
    else:
        print("Opci√≥n inv√°lida, usando servidor est√°ndar...")
        server_url = "http://localhost:8082"
    
    print(f"\\nüîç Verificando servidor en {server_url}...")
    
    if is_server_responding(server_url):
        print(f"‚úÖ Servidor disponible: {servers.get(choice, ('', 'Servidor Personalizado'))[1]}")
        test_server_latency_safe(server_url)
    else:
        print(f"‚ùå Servidor no disponible en {server_url}")
        print("   Verifica que el servidor est√© corriendo antes de ejecutar la prueba")


if __name__ == "__main__":
    main()