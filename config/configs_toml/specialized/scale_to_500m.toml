[scaling]
source_model = "300m_checkpoint"
target_size = 500000000
hidden_size = 1024
num_heads = 16
num_layers = 32

[training]
precision = "fp32_fp16"
batch_size = 32
learning_rate = "5e-5"
warmup_steps = 2000
gradient_clip_method = "adaptive"
gradient_clip_norm = 1.0
gradient_clip_adaptive_threshold = 0.1

[training.gradient_clip_per_layer_norm]
attention = 0.5
mlp = 1.0
embedding = 2.0
