#!/usr/bin/env python3
"""
Optimizaci√≥n adicional: Habilitar sistema de consenso para mejorar la latencia y calidad
"""

import json
import os
from pathlib import Path

def enable_consensus_optimization():
    """
    Habilita el sistema de consenso en la configuraci√≥n para mejorar la calidad
    de las respuestas y potencialmente reducir la latencia mediante inferencia paralela
    """
    config_path = "/home/elect/capibara6/arm-axion-optimizations/vllm_integration/config.json"
    
    # Cargar configuraci√≥n actual
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    print("üöÄ Habilitando sistema de consenso...")
    
    # Actualizar la configuraci√≥n para habilitar consenso
    config['enable_consensus'] = True
    
    # Configurar un modelo para consenso si no existe
    if not config.get('consensus_model'):
        # Por defecto usar un modelo ligero para consenso
        config['consensus_model'] = "/home/elect/models/phi-4-mini"  # Modelo r√°pido para s√≠ntesis
    
    # Asegurar que speculative routing est√© habilitado para mejor latencia
    if 'speculative_routing' not in config:
        config['speculative_routing'] = {
            "enabled": True,
            "speculation_threshold": 0.85,
            "max_speculation_time": 0.5
        }
    
    # Guardar la configuraci√≥n actualizada
    backup_path = config_path.replace(".json", ".with_consensus.backup")
    with open(backup_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"‚úÖ Sistema de consenso habilitado en {config_path}")
    print(f"   Backup original en: {backup_path}")
    print(f"   Consenso: {config['enable_consensus']}")
    print(f"   Modelo de consenso: {config.get('consensus_model', 'no especificado')}")
    
    return config_path, backup_path


def update_livemind_orchestrator_consensus():
    """
    Actualiza el orchestrator para habilitar consenso por defecto
    """
    orchestrator_path = "/home/elect/capibara6/arm-axion-optimizations/vllm_integration/livemind_orchestrator.py"
    
    # Leer el archivo actual
    with open(orchestrator_path, 'r') as f:
        content = f.read()
    
    print("üîÑ Actualizando LiveMind Orchestrator para habilitar consenso...")
    
    # Cambiar enable_consensus por defecto de False a True en la l√≠nea de inicializaci√≥n
    updated_content = content.replace(
        "enable_consensus: bool = False,", 
        "enable_consensus: bool = True,"
    )
    
    # Actualizar tambi√©n en el ejemplo de inicializaci√≥n al final del archivo
    updated_content = updated_content.replace(
        "enable_consensus=False,",
        "enable_consensus=True,"
    )
    
    # Guardar el archivo actualizado
    backup_path = orchestrator_path.replace(".py", ".with_consensus.backup")
    with open(backup_path, 'w') as f:
        f.write(content)
    
    with open(orchestrator_path, 'w') as f:
        f.write(updated_content)
    
    print(f"‚úÖ LiveMind Orchestrator actualizado en {orchestrator_path}")
    print(f"   Backup original en: {backup_path}")
    
    return orchestrator_path, backup_path


def create_consensus_test():
    """
    Crea un script de prueba para verificar la funcionalidad de consenso
    """
    test_content = '''
#!/usr/bin/env python3
"""
Prueba de funcionalidad de consenso
"""

import requests
import time
import json

def test_consensus_functionality():
    """
    Prueba que el sistema de consenso est√© funcionando
    """
    print("üß™ Probando funcionalidad de consenso...")
    
    # Verificar estado del servidor
    try:
        response = requests.get("http://localhost:8082/stats", timeout=10)
        if response.status_code == 200:
            stats = response.json()
            print(f"‚úÖ Servidor estado: {stats}")
            
            # Verificar si el consenso est√° habilitado
            if "config" in stats:
                consensus_enabled = stats["config"].get("enable_consensus", False)
                print(f"üìä Consenso habilitado: {consensus_enabled}")
                
                if consensus_enabled:
                    print("‚úÖ Sistema de consenso est√° activado")
                else:
                    print("‚ö†Ô∏è  Sistema de consenso no est√° activado")
            else:
                print("‚ö†Ô∏è  No se pudo verificar estado de consenso")
        else:
            print(f"‚ùå Error al obtener estado: {response.status_code}")
    except Exception as e:
        print(f"‚ùå Error al conectar con servidor: {e}")
    
    # Probar una solicitud simple
    try:
        print("\\nüìù Enviando solicitud de prueba...")
        response = requests.post(
            "http://localhost:8082/v1/chat/completions",
            json={
                "model": "",  # Dejar vac√≠o para usar router autom√°tico
                "messages": [
                    {"role": "user", "content": "¬øCu√°l es el modelo m√°s apropiado para tareas de codificaci√≥n?"}
                ],
                "max_tokens": 50,
                "temperature": 0.7
            },
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"‚úÖ Respuesta recibida: {len(result.get('choices', []))} opciones")
            if result.get('choices'):
                content = result['choices'][0].get('message', {}).get('content', '')[:100]
                print(f"üìÑ Contenido (primeros 100 chars): {content}...")
        else:
            print(f"‚ùå Error en la solicitud: {response.status_code}, {response.text}")
            
    except Exception as e:
        print(f"‚ùå Error en la prueba: {e}")

if __name__ == "__main__":
    test_consensus_functionality()
'''
    
    test_path = "/home/elect/capibara6/test_consensus_functionality.py"
    with open(test_path, 'w') as f:
        f.write(test_content)
    
    # Hacerlo ejecutable
    os.chmod(test_path, 0o755)
    
    print(f"‚úÖ Script de prueba de consenso creado en {test_path}")
    
    return test_path


def main():
    print("üéØ IMPLEMENTACI√ìN DE CONSENSO PARA REDUCIR LATENCIA")
    print("=" * 60)
    print("La estrategia de consenso paralelo puede mejorar la latencia al:")
    print("- Permitir inferencia paralela en m√∫ltiples especialistas")
    print("- Sintetizar respuestas de m√∫ltiples modelos")
    print("- Mejorar calidad de respuestas sin aumentar latencia significativamente")
    print("=" * 60)
    
    # 1. Habilitar consenso en la configuraci√≥n
    config_path, config_backup = enable_consensus_optimization()
    
    # 2. Actualizar el orchestrator
    orchestrator_path, orchestrator_backup = update_livemind_orchestrator_consensus()
    
    # 3. Crear script de prueba
    test_path = create_consensus_test()
    
    print("\\nüìã RESUMEN DE CAMBIOS:")
    print(f"   ‚Ä¢ Configuraci√≥n actualizada: {config_path}")
    print(f"   ‚Ä¢ Orchestrator actualizado: {orchestrator_path}")
    print(f"   ‚Ä¢ Script de prueba: {test_path}")
    print(f"   ‚Ä¢ Backups creados para reversi√≥n si es necesario")
    
    print("\\nüí° NOTA: Para que los cambios surtan efecto, reinicie el servidor con:")
    print("   pkill -f multi_model_server  # Detener servidores anteriores")
    print("   cd /home/elect/capibara6/arm-axion-optimizations/vllm_integration")
    print("   python3 multi_model_server.py --host 0.0.0.0 --port 8082 --config config.json &")
    
    print("\\nüß™ Para probar la funcionalidad de consenso:")
    print(f"   python3 {test_path}")
    
    print("\\n‚úÖ Optimizaci√≥n de consenso implementada exitosamente!")


if __name__ == "__main__":
    main()