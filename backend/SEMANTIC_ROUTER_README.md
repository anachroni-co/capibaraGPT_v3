# Semantic Router - Capibara6

Selecci√≥n autom√°tica e inteligente de modelos AI basada en an√°lisis sem√°ntico de las consultas del usuario.

## üéØ ¬øQu√© es?

El **Semantic Router** analiza el significado sem√°ntico de cada consulta y selecciona autom√°ticamente el modelo de IA m√°s adecuado para responder. Esto optimiza la calidad de las respuestas y el uso de recursos.

### Ventajas

- ‚ö° **Ultra-r√°pido**: Decisi√≥n instant√°nea sin latencia de LLM
- üéØ **Preciso**: Usa embeddings sem√°nticos, no reglas simples
- üí∞ **Sin costos**: Funciona 100% local con FastEmbed
- üß† **Inteligente**: Entiende el significado, no solo palabras clave
- üìä **Transparente**: El frontend sabe qu√© modelo se us√≥

---

## üì¶ Instalaci√≥n

### 1. Instalar semantic-router

```bash
cd backend
pip install "semantic-router[local]"
```

Esto instala:
- `semantic-router` - La librer√≠a principal
- `fastembed` - Encoder local (sin API keys)

### 2. Verificar instalaci√≥n

```bash
python -c "import semantic_router; print('‚úÖ Instalado correctamente')"
```

---

## üöÄ Uso

### Arrancar servidor con Semantic Router

```bash
cd backend
python capibara6_integrated_server.py
```

Al iniciar, ver√°s:

```
============================================================
üöÄ Iniciando Servidor Integrado Capibara6...
============================================================
üì° VM GPT-OSS-20B: http://34.175.215.109:8080/completion
üß† Smart MCP: Activo
üéµ Coqui TTS: Activo
üéØ Semantic Router: ‚úÖ Activo
ü§ñ Models Config: ‚úÖ Activo
üåê Puerto: 5001

üìã Semantic Router configurado:
   ‚Ä¢ Rutas: 7 (programming, creative_writing, quick_facts...)
   ‚Ä¢ Modelos: 8
============================================================
```

---

## üß™ Testing

### 1. Test completo

Prueba todas las categor√≠as:

```bash
cd backend
python test_semantic_router.py
```

Output:
```
üß™ Test Suite - Semantic Router Capibara6
...
üìä Estad√≠sticas Globales
üìù Total de queries probadas: 35
üéØ Queries con ruta espec√≠fica: 32
‚ö†Ô∏è  Queries con fallback: 3

üó∫Ô∏è  Distribuci√≥n por Rutas:
   ‚Ä¢ programming          8 queries (22.9%)
   ‚Ä¢ creative_writing     5 queries (14.3%)
   ‚Ä¢ quick_facts          5 queries (14.3%)
...
```

### 2. Modo interactivo

```bash
python test_semantic_router.py --interactive
```

```
Query > c√≥mo programar en Python
‚Üí Query: "c√≥mo programar en Python"
   ‚îú‚îÄ Ruta detectada: programming
   ‚îú‚îÄ Modelo: gpt-oss-20b
   ‚îú‚îÄ Confianza: 90%
   ‚îú‚îÄ Fallback: No
   ‚îî‚îÄ Raz√≥n: Query clasificada como 'programming' ‚Üí usando gpt-oss-20b

Query > quit
```

### 3. Test de una categor√≠a

```bash
python test_semantic_router.py --category "Programming"
```

### 4. Test de una query

```bash
python test_semantic_router.py --query "escribe un cuento sobre el espacio"
```

---

## üó∫Ô∏è Rutas y Modelos

El router clasifica queries en las siguientes categor√≠as:

| Ruta | Modelo Asignado | Ejemplos |
|------|----------------|----------|
| **programming** | `gpt-oss-20b` | "c√≥mo programar en Python", "debug este c√≥digo" |
| **creative_writing** | `mixtral` | "escribe un cuento", "crea un poema" |
| **quick_facts** | `phi` | "qu√© es Python", "qui√©n descubri√≥ Am√©rica" |
| **analysis** | `gpt-oss-20b` | "analiza las diferencias entre...", "compara..." |
| **conversation** | `phi` | "hola", "h√°blame de ti" |
| **math** | `gpt-oss-20b` | "resuelve 25 + 37", "calcula el √°rea" |
| **translation** | `mixtral` | "traduce esto al ingl√©s" |
| **default** | `gpt-oss-20b` | Queries que no matchean ninguna ruta |

---

## üîß Configuraci√≥n

### Modificar rutas

Edita `backend/semantic_model_router.py`:

```python
Route(
    name="mi_nueva_ruta",
    utterances=[
        "ejemplo 1",
        "ejemplo 2",
        "ejemplo 3"
    ]
)
```

### Cambiar asignaci√≥n de modelos

```python
self.model_mapping = {
    "programming": "gpt-oss-20b",  # Cambiar a otro modelo
    "creative_writing": "mixtral",
    # ...
}
```

### Agregar nuevos modelos

Edita `backend/models_config.py`:

```python
'mi-modelo': {
    'name': 'Mi Modelo',
    'base_model': 'Base Model Name',
    'server_url': 'http://ip:puerto/completion',
    'type': 'llama_cpp',
    'hardware': 'GPU',
    'status': 'active',
    'priority': 1,
    'prompt_template': { ... },
    'parameters': { ... }
}
```

---

## üåê API Endpoints

### 1. POST `/api/chat` - Chat con selecci√≥n autom√°tica

**Request:**
```json
{
  "message": "c√≥mo programar en Python",
  "use_semantic_router": true
}
```

**Response:**
```json
{
  "response": "Python es un lenguaje...",
  "model": "gpt-oss-20b",
  "tokens": 150,
  "routing_info": {
    "model_id": "gpt-oss-20b",
    "route_name": "programming",
    "confidence": 0.9,
    "reasoning": "Query clasificada como 'programming' ‚Üí usando gpt-oss-20b",
    "fallback": false
  }
}
```

### 2. GET `/api/router/info` - Info del router

```bash
curl http://localhost:5001/api/router/info
```

**Response:**
```json
{
  "enabled": true,
  "routes": ["programming", "creative_writing", ...],
  "model_mapping": { "programming": "gpt-oss-20b", ... },
  "encoder": "FastEmbed (local)",
  "status": "active",
  "models_configured": 8
}
```

### 3. POST `/api/router/test` - Probar routing

```bash
curl -X POST http://localhost:5001/api/router/test \
  -H "Content-Type: application/json" \
  -d '{"query": "escribe un cuento"}'
```

**Response:**
```json
{
  "query": "escribe un cuento",
  "decision": {
    "model_id": "mixtral",
    "route_name": "creative_writing",
    "confidence": 0.9,
    "reasoning": "Query clasificada como 'creative_writing' ‚Üí usando mixtral",
    "fallback": false
  }
}
```

### 4. GET `/api/router/routes` - Ver todas las rutas

```bash
curl http://localhost:5001/api/router/routes
```

### 5. GET `/api/router/models` - Ver todos los modelos

```bash
curl http://localhost:5001/api/router/models
```

---

## üé® Integraci√≥n Frontend

### Mostrar modelo usado en UI

```javascript
async function sendMessage(message) {
    const response = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
            message,
            use_semantic_router: true
        })
    });

    const data = await response.json();

    // Mostrar informaci√≥n de routing
    if (data.routing_info) {
        console.log(`üéØ Modelo: ${data.model}`);
        console.log(`üìç Ruta: ${data.routing_info.route_name}`);
        console.log(`üí≠ Confianza: ${(data.routing_info.confidence * 100).toFixed(0)}%`);

        // Opcional: mostrar badge en UI
        showModelBadge(data.model, data.routing_info.route_name);
    }

    return data.response;
}
```

### Deshabilitar routing temporalmente

```javascript
fetch('/api/chat', {
    method: 'POST',
    body: JSON.stringify({
        message: "test",
        use_semantic_router: false  // Usar modelo por defecto
    })
});
```

---

## üìä Modelos Configurados (Backend BB)

Actualmente hay **3 modelos activos** en el backend BB:

| ID | Nombre | Par√°metros | Hardware | Puerto | Uso |
|----|--------|------------|----------|--------|-----|
| `gpt-oss-20b` | GPT-OSS-20B | 20B | GPU | 8080 | Programaci√≥n/Matem√°ticas/An√°lisis/Default |
| `phi` | Phi-3 Mini | 3.8B | GPU | 8081 | Facts r√°pidos/Conversaci√≥n |
| `mixtral` | Mixtral 8x7B | ~47B | GPU | 8082 | Creatividad/Traducci√≥n |

---

## üêõ Troubleshooting

### Error: "Semantic Router no disponible"

**Soluci√≥n:**
```bash
pip install "semantic-router[local]"
```

### Error: "No module named 'fastembed'"

**Soluci√≥n:**
```bash
pip install fastembed
```

### Router siempre usa modelo por defecto

**Posibles causas:**
1. Las queries no matchean ninguna ruta
2. Los ejemplos (`utterances`) necesitan mejorarse

**Soluci√≥n:**
```bash
# Probar query espec√≠fica
python test_semantic_router.py --query "tu consulta aqu√≠"

# Agregar m√°s ejemplos en semantic_model_router.py
```

### Modelos no disponibles

Si alg√∫n modelo no est√° corriendo en su puerto:
1. El router seleccionar√° el modelo igual
2. La petici√≥n fallar√° con error 502/504
3. Verifica que los modelos est√©n corriendo:

```bash
# Verificar puertos
lsof -i :8080
lsof -i :8081
lsof -i :8082
```

---

## üîÑ Actualizar

```bash
cd backend
pip install --upgrade semantic-router
```

---

## üìö Referencias

- [Semantic Router GitHub](https://github.com/gmarko/semantic-router)
- [FastEmbed Documentation](https://qdrant.github.io/fastembed/)
- Configuraci√≥n de modelos: `backend/models_config.py`
- Router implementation: `backend/semantic_model_router.py`

---

## üÜò Soporte

Si tienes problemas:

1. Revisa logs del servidor: `python capibara6_integrated_server.py`
2. Prueba con: `python test_semantic_router.py --interactive`
3. Verifica instalaci√≥n: `pip list | grep semantic-router`
4. Consulta documentaci√≥n: `backend/SEMANTIC_ROUTER_README.md`

---

**√öltima actualizaci√≥n**: Noviembre 2025
**Versi√≥n**: 1.0.0
