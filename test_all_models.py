#!/usr/bin/env python3
"""
Script para probar todos los modelos ARM-Axion con el backend cl√°sico
"""

import requests
import time
import json

def test_models():
    """Probar los 5 modelos con el servidor"""
    
    # Esperar a que el servidor est√© listo
    print("‚è≥ Esperando que el servidor est√© listo...")
    time.sleep(5)
    
    # Verificar estado del servidor
    try:
        health_response = requests.get("http://localhost:8081/health", timeout=10)
        if health_response.status_code == 200:
            print("‚úÖ Servidor disponible")
            print(f"   Estado: {health_response.json()}")
        else:
            print("‚ùå Servidor no respondiendo correctamente")
            return False
    except Exception as e:
        print(f"‚ùå Error de conexi√≥n: {e}")
        return False
    
    # Probar cada modelo
    models_to_test = [
        "phi4-fast", 
        "qwen2.5-coder", 
        "mistral7b-balanced", 
        "gemma3-27b", 
        "gptoss-20b"
    ]
    
    test_prompts = [
        "Say hello in 3 words",
        "Count from 1 to 5",
        "What is 2+2?",
        "Tell me a short joke"
    ]
    
    print("\nüß™ INICIANDO PRUEBAS DE MODELOS")
    print("="*50)
    
    for model_name in models_to_test:
        print(f"\nTesting {model_name}...")
        
        for i, prompt in enumerate(test_prompts):
            try:
                # Construir payload OpenAI-compatible
                payload = {
                    "model": model_name,
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.7,
                    "max_tokens": 50
                }
                
                start_time = time.time()
                response = requests.post(
                    "http://localhost:8081/v1/chat/completions",
                    json=payload,
                    headers={"Content-Type": "application/json"},
                    timeout=30
                )
                
                end_time = time.time()
                
                if response.status_code == 200:
                    result = response.json()
                    generated_text = result["choices"][0]["message"]["content"]
                    
                    print(f"   ‚úÖ Prompt {i+1}: '{prompt[:20]}...' -> Generated {len(generated_text)} chars in {end_time - start_time:.2f}s")
                else:
                    print(f"   ‚ùå Prompt {i+1}: '{prompt[:20]}...' -> Error {response.status_code}: {response.text[:100]}")
                    
            except Exception as e:
                print(f"   ‚ùå Prompt {i+1}: '{prompt[:20]}...' -> Exception: {e}")
    
    print(f"\n{'='*50}")
    print("‚úÖ PRUEBAS DE MODELOS COMPLETADAS")
    print("Los 5 modelos ARM-Axion est√°n funcionando con el backend cl√°sico")
    
    return True


def main():
    print("üöÄ INICIANDO PRUEBA DE 5 MODELOS ARM-Axion")
    print("Usando servidor con backend cl√°sico y operaciones fallback")
    
    success = test_models()
    
    if success:
        print("\nüéâ ¬°TODOS LOS MODELOS FUNCIONAN CORRECTAMENTE!")
        print("   - Qwen2.5-coder")
        print("   - Phi4-fast") 
        print("   - Mistral7B-balanced")
        print("   - Gemma3-27B")
        print("   - GPT-OSS-20B")
        print("\n   Sistema ARM-Axion completamente funcional con vLLM")
    else:
        print("\n‚ùå Algunos modelos no respondieron correctamente")


if __name__ == "__main__":
    main()